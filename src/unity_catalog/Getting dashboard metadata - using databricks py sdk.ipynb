{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef31ee1e-aeb2-45b5-8478-af92d929ab75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Extracting the metadata for AI+BI dashboards on a Databricks workspace\n",
    "\n",
    "This example uses the databricks-cli package to get all the details about dashboards deployed on a workspace.\n",
    "\n",
    "1. makes a request to get the list of dashboards,\n",
    "2. iterates over each dashboard to get its details, permissions, and published details,\n",
    "3. handles exceptions for missing published details\n",
    "4. It writes dashboard details into a Databricks Delta table\n",
    "5. Finally it queries the table and displays the first 50 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de073939-c3f5-4235-aaae-c43c51e49d33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install the databricks-cli package\n",
    "%pip install databricks-cli\n",
    "\n",
    "from databricks_cli.sdk import ApiClient\n",
    "import pandas as pd\n",
    "\n",
    "# Get the token stored using dbutils\n",
    "token = dbutils.secrets.get(scope=\"my_scope\", key=\"my_personal_access_token\")\n",
    "\n",
    "# Initialize the API client with the host and token\n",
    "host = \"https://<my_databricks_host_url>\"\n",
    "api_client = ApiClient(host=host, token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb84fadb-4877-42e6-b872-798fd26af7ad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get metadata for dashboards - v1 (first 20 only)"
    }
   },
   "outputs": [],
   "source": [
    "# Simple example that gets list of dashboards, permissions, details, published_details. \n",
    "# Refer to the next cell for V2 that persists all details extracted into a table and also handles exceptions\n",
    "\n",
    "# Define the endpoint for listing dashboards\n",
    "endpoint = \"/lakeview/dashboards\"\n",
    "\n",
    "# Make the request to get the list of dashboards\n",
    "response = api_client.perform_query(\"GET\", endpoint)\n",
    "\n",
    "# Extract the list of dashboards from the response\n",
    "dashboards = response.get('dashboards', [])\n",
    "\n",
    "# Initialize a list to store dashboard details\n",
    "dashboard_details = []\n",
    "\n",
    "# Iterate over each dashboard to get dashboard details\n",
    "for dashboard in dashboards:\n",
    "    dashboard_id = dashboard.get('dashboard_id')\n",
    "    \n",
    "    # Get permissions for the dashboard\n",
    "    permissions_endpoint = f\"/permissions/dashboards/{dashboard_id}\"\n",
    "    permissions_response = api_client.perform_query(\"GET\", permissions_endpoint)\n",
    "    dashboard['permissions'] = permissions_response\n",
    "    \n",
    "    # Get dashboard details\n",
    "    dashboard_details_endpoint = f\"/lakeview/dashboards/{dashboard_id}\"\n",
    "    dashboard_details_response = api_client.perform_query(\"GET\", dashboard_details_endpoint)\n",
    "    dashboard['details'] = dashboard_details_response\n",
    "    \n",
    "    # Get dashboard published_details\n",
    "    dashboard_published_details_endpoint = f\"/lakeview/dashboards/{dashboard_id}/published\"\n",
    "    try:\n",
    "        dashboard_published_details_response = api_client.perform_query(\"GET\", dashboard_published_details_endpoint)\n",
    "    except Exception as e:\n",
    "        if \"404\" in str(e):\n",
    "                dashboard_published_details_response = {'error': str(e), 'details': {\"error_code\": \"NOT_FOUND\", \"message\": f\"Unable to find published dashboard [dashboardId={dashboard_id}]\"}}\n",
    "        else:\n",
    "            dashboard_published_details_response = str(e)\n",
    "    dashboard['published_details'] = dashboard_published_details_response\n",
    "\n",
    "    dashboard_details.append(dashboard)\n",
    "\n",
    "# Create a DataFrame from the dashboard details\n",
    "df_dashboards = pd.DataFrame(dashboard_details)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_dashboards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bd9bed0-758d-4644-9b4d-35eb73010d7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Initialize the table . Drop table if exists\n",
    "table_name = \"main.default.dashboard_metadata\"\n",
    "spark.sql(f\"drop table if exists {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "744350e7-8267-44b0-9e2c-d5be28b77096",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get metadata for dashboards v2"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, MapType, ArrayType,DateType, BooleanType\n",
    ")\n",
    "\n",
    "# Define the schema for the DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"metadata_sync_id\", StringType(), True),\n",
    "    StructField(\"dashboard_id\", StringType(), True),\n",
    "    StructField(\"display_name\", StringType(), True),\n",
    "    StructField(\"create_time\", StringType(), True),\n",
    "    StructField(\"warehouse_id\", StringType(), True),\n",
    "    StructField(\"lifecycle_state\", StringType(), True),\n",
    "    StructField(\"published\", BooleanType(), True),\n",
    "    StructField(\"permissions\", MapType(StringType(), StringType()), True),\n",
    "    StructField(\"details\", MapType(StringType(), StringType()), True),\n",
    "    StructField(\"published_details\", MapType(StringType(), StringType()), True)\n",
    "])\n",
    "\n",
    "# Define the endpoint for listing dashboards\n",
    "endpoint = \"/lakeview/dashboards?page_size=200\"\n",
    "\n",
    "# Initialize a list to store all dashboard details\n",
    "all_dashboard_details = []\n",
    "\n",
    "# Initialize a sync id to track the sync status\n",
    "metadata_sync_id = \"20250219-1\"\n",
    "\n",
    "#Initialize the table name\n",
    "table_name = \"main.default.dashboard_metadata\"\n",
    "\n",
    "# Function to get dashboard details\n",
    "def get_dashboard_details(endpoint):\n",
    "    # Make the request to get the list of dashboards\n",
    "    response = api_client.perform_query(\"GET\", endpoint)\n",
    "\n",
    "    # Extract the list of dashboards from the response\n",
    "    dashboards = response.get('dashboards', [])\n",
    "    \n",
    "    # Iterate over each dashboard to get dashboard details\n",
    "    for dashboard in dashboards:\n",
    "        dashboard_id = dashboard.get('dashboard_id')\n",
    "        \n",
    "        # Get permissions for the dashboard\n",
    "        permissions_endpoint = f\"/permissions/dashboards/{dashboard_id}\"\n",
    "        try:\n",
    "            permissions_response = api_client.perform_query(\"GET\", permissions_endpoint)\n",
    "        except Exception as e:\n",
    "            permissions_response = {'error': str(e), 'details': {}}\n",
    "        dashboard['permissions'] = permissions_response\n",
    "        \n",
    "        # Get dashboard details\n",
    "        dashboard_details_endpoint = f\"/lakeview/dashboards/{dashboard_id}\"\n",
    "        try:\n",
    "            dashboard_details_response = api_client.perform_query(\"GET\", dashboard_details_endpoint)\n",
    "        except Exception as e:\n",
    "            dashboard_details_response =  {'error': str(e), 'details': {}}\n",
    "        dashboard['details'] = dashboard_details_response\n",
    "\n",
    "        # Get dashboard published_details\n",
    "        dashboard_published_details_endpoint = f\"/lakeview/dashboards/{dashboard_id}/published\"\n",
    "        try:\n",
    "            dashboard_published_details_response = api_client.perform_query(\"GET\", dashboard_published_details_endpoint)\n",
    "            dashboard['published'] =True\n",
    "        except Exception as e:\n",
    "            if \"404\" in str(e):\n",
    "                dashboard_published_details_response = {'error': str(e), 'details': {\"error_code\": \"NOT_FOUND\", \"message\": f\"Unable to find published dashboard [dashboardId={dashboard_id}]\"}}\n",
    "                dashboard['published'] = False\n",
    "            else:\n",
    "                dashboard_published_details_response = {'error': str(e), 'details': {}}\n",
    "                dashboard['published'] = False\n",
    "\n",
    "        dashboard['published_details'] = dashboard_published_details_response\n",
    "\n",
    "        # set a sync id. This enables writing to the table and querying based on sync_id\n",
    "        dashboard['metadata_sync_id'] = metadata_sync_id\n",
    "\n",
    "        all_dashboard_details.append(dashboard)\n",
    "\n",
    "    # Append to table\n",
    "    df_all_dashboards_spark = spark.createDataFrame(all_dashboard_details, schema=schema)\n",
    "    df_all_dashboards_spark.write.mode(\"append\").saveAsTable(table_name)\n",
    "\n",
    "    next_page_token = response.get('next_page_token')\n",
    "    return next_page_token\n",
    "\n",
    "# Initial call to get dashboard details\n",
    "next_page_token = get_dashboard_details(endpoint)\n",
    "\n",
    "# Initialize a counter for the number of next_page_tokens processed\n",
    "token_counter = 0\n",
    "\n",
    "# Call the API again if next_page_token is not null and counter is less than 2\n",
    "while next_page_token and token_counter < 2000:\n",
    "    next_page_endpoint = f\"{endpoint}&page_token={next_page_token}\"\n",
    "    print(\"Processing: \" + next_page_endpoint)\n",
    "    next_page_token = get_dashboard_details(next_page_endpoint)\n",
    "    token_counter += 1\n",
    "\n",
    "# Display the DataFrame\n",
    "#display(spark.createDataFrame(all_dashboard_details, schema=schema).limit(50))\n",
    "\n",
    "# Display data from the table\n",
    "spark.sql(f\"select * from {table_name} limit 50\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Getting dashboard metadata - using databricks py sdk",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}